# not really using GPU so
- reduced number of workers to 10 (instead of default to 24) - train.py
- increased the number of cores to 12 (n) - train.sh 

# if still really slow
- reduce the batch_size from 64 to 32
- increase the learning rate from 1e-4 to 1e-3
- eventually also reduce the latent space from 32 to maybe 24 or 26, but is this worse than other two options

# change to params of chambon paper
- batch size 128
- learning 0.001

# changes in the physioEx library
base.py line 41/42 num_classes= self.n_classes,

test.py line 42     seq_length = model_config['sequence_length']
and adding the seq length to the results names f"results-{seq_length}.csv" key+f"{seq_length}.png"

train changing the model name also adding seq_length seq_length = str(model_config['sequence_length'])
filename="fold=%d-{epoch}-{step}-{val_acc:.2f}" % fold + "-" + seq_length

# Symu datasets
Train_1 and Test_1
fs = 1000, T = 1s
# freqs_1 = [50, 100, 320, 60, 480]
# freqs_2 = [50, 480, 320, 60, 100] 
# times = [0.1, 0.2, 0.4, 0.4, 0.7]
# ampls = [1, 0.9, 0.8, 0.8, 1]

5 iterations of signal generation for train
1 iteration of signal generation for test

with model 3 trained on this data

Train_2 and Test_2
fs = 16, T = 1s
# freqs_0 = [2]
# freqs_1 = [6] 
# times_0 = [0.3]
# times_1 = [0.7]
# ampls = [1]

5 iterations of signal generation for train
2 iteration of signal generation for test

with model 4 trained on this data

Train_3 and Test_3
fs = 16, T = 1s
freqs_0 = 2Hz
freqs_1 = 6Hz
time = 0.3
ampl = 1

5 iterations of signal generations for train and filtered with either LP or HP (3, 5) cutoff freq
1 iteration of signal generation for test and filtered with either LP or HP (3, 5) cutoff freq

results stored in flextime_64_9_128_3
and wavelet_db1_4_128_results_3
wavelet_db1_4_128_results_3_rescaled
wavelet_db1_4_128_results_3_normalized
with model 5 trained on this data

prior to this point data simu seed 33 and train/test seed in 42
from now on everything seeded 42 :)

